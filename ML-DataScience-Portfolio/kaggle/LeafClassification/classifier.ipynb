{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "0   1  Acer_Opalus  0.007812  0.023438  0.023438  0.003906  0.011719   \n",
       "\n",
       "    margin6   margin7  margin8    ...      texture55  texture56  texture57  \\\n",
       "0  0.009766  0.027344      0.0    ...       0.007812        0.0    0.00293   \n",
       "\n",
       "   texture58  texture59  texture60  texture61  texture62  texture63  texture64  \n",
       "0    0.00293   0.035156        0.0        0.0   0.004883        0.0   0.025391  \n",
       "\n",
       "[1 rows x 194 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(train.species)\n",
    "labels = le.transform(train.species)\n",
    "classes = le.classes_\n",
    "test_ids = test.id\n",
    "train = train.drop(['species', 'id'], axis = 1)\n",
    "test = test.drop(['id'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(labels, 10, test_size=0.1, random_state=23)\n",
    "\n",
    "for train_index, test_index in sss:\n",
    "    X_train, X_test = train.values[train_index], train.values[test_index]\n",
    "    Y_train, Y_test = labels[train_index], labels[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/Library/Python/2.7/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train, Y_train)\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.9798%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: {:.4%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clfNN = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(192, 192), random_state=1)\n",
    "clfNN.fit(X_train, Y_train)\n",
    "predictionsNN = clfNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.4242%\n"
     ]
    }
   ],
   "source": [
    "accNN = accuracy_score(Y_test, predictionsNN)\n",
    "print(\"Accuracy: {:.4%}\".format(accNN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 192)\n",
      "(891, 99)\n",
      "(891, 192)\n"
     ]
    }
   ],
   "source": [
    "#starting with keras NN\n",
    "#One hot encoding for labels\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "labelOneHot = to_categorical(Y_train)\n",
    "labelOneHotTest = to_categorical(Y_test)\n",
    "# Standardising the data to give zero mean\n",
    "X_NN = StandardScaler().fit(X_train).transform(X_train)\n",
    "X_testNN = StandardScaler().fit(X_test).transform(X_test)\n",
    "print(X_NN.shape)\n",
    "print labelOneHot.shape\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import keras.layers.convolutional as conv\n",
    "model = Sequential()\n",
    "#model.add(conv.Convolution1D(64,3,border_mode='same', input_shape=(192, 1024)))\n",
    "model.add(Dense(1500,input_dim=192,  init='glorot_uniform', activation='relu'))\n",
    "#model.add(Dense(1024, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(700, activation='sigmoid'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(99, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#using all the training data for NN\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics = [\"accuracy\"])\n",
    "filepath=\"weights.best.hdf5\"\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#using keras callback function to save best model during epochs\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]\n",
    "#history = model.fit(X_NN,labelOneHot,batch_size=192,nb_epoch=120,callbacks=callbacks_list, verbose=0, validation_split=0.1)\n",
    "history = model.fit(X_NN,labelOneHot,batch_size=80,nb_epoch=150, verbose=0, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('val_acc: ', 1.0)\n",
      "('val_loss: ', 0.0059320637956261635)\n",
      "('acc: ', 1.0)\n",
      "('loss: ', 1.1920928955078125e-07)\n",
      "acc: 99.49%\n"
     ]
    }
   ],
   "source": [
    "print('val_acc: ',min(history.history['val_acc']))\n",
    "print('val_loss: ',min(history.history['val_loss']))\n",
    "print('acc: ',max(history.history['acc']))\n",
    "print('loss: ',min(history.history['loss']))\n",
    "scores = model.evaluate(X_testNN, labelOneHotTest, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99.49%\n"
     ]
    }
   ],
   "source": [
    "#loading our best saved model\n",
    "modelLoad = Sequential()\n",
    "modelLoad.add(Dense(1024,input_dim=192,  init='uniform', activation='relu'))\n",
    "modelLoad.add(Dropout(0.3))\n",
    "modelLoad.add(Dense(512, activation='sigmoid'))\n",
    "modelLoad.add(Dropout(0.3))\n",
    "modelLoad.add(Dense(99, activation='softmax'))\n",
    "modelLoad.load_weights(\"weights.best.hdf5\")\n",
    "modelLoad.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics = [\"accuracy\"])\n",
    "modelLoad = modelLoad.evaluate(X_testNN, labelOneHotTest, verbose=0)\n",
    "print(\" %.2f%%\" % ( modelLoad[1]*100))\n",
    "#this did not increase accuracy,so not using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2b79d60d88b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtestNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictionsNNprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionsNNprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "testNN = StandardScaler().fit(test).transform(test)\n",
    "predictionsNNprob = model.predict_proba(testNN)\n",
    "\n",
    "submission = pd.DataFrame(predictionsNNprob, columns=classes)\n",
    "submission.insert(0, 'id', test_ids)\n",
    "submission.reset_index()\n",
    "# Export Submission\n",
    "submission.to_csv('submission.csv', index = False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(594, 100)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing adaboost\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "clf2 =  AdaBoostClassifier()\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.9798%\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: {:.4%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.4949%\n"
     ]
    }
   ],
   "source": [
    "#using regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs',multi_class='multinomial', C=1000, tol=0.0008)\n",
    "clf.fit(X_NN, Y_train)\n",
    "predictions = clf.predict(X_testNN)\n",
    "acc = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: {:.4%}\".format(acc))\n",
    "y_test = clf.predict_proba(testNN)\n",
    "\n",
    "submission = pd.DataFrame(y_test, index=test_ids, columns=le.classes_)\n",
    "#submission.to_csv('submission_log_reg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.4747%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clfL = linear_model.SGDClassifier()\n",
    "clfL.fit(X_NN, Y_train)\n",
    "predictions = clfL.predict(X_testNN)\n",
    "acc = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: {:.4%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-03690cb5ffa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodelX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_NN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_testNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: {:.4%}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "modelX = XGBClassifier()\n",
    "modelX.fit(X_NN, Y_train)\n",
    "predictions = modelX.predict(X_testNN)\n",
    "acc = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: {:.4%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.8687%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: {:.4%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
